---
title: |
  | Final Project
  | DS 805: Statistical Learning
author: |
  | Sharmishta, Srija, Divya
output: html_document
---

```{r setup, include=FALSE, tidy=TRUE}
knitr::opts_chunk$set(echo = TRUE)
options("kableExtra.html.bsTable" = T)

library(MASS)
library(forecast) 
library(ggplot2)
library(ggfortify)
library(kableExtra)
library(car)
library(formatR)
library(rpart)
library(rpart.plot)
library(caret)
library(Metrics)
library(ipred)
library(randomForest)
library(vip)
library(ipred)
library(ISLR)
library(boot)
library(leaps)
library(purrr)
library(glmnet)
library(pls)
library(lattice)
library(ggvis) 
library(nnet)
library(pROC)
library(class)
library(magrittr)
library(dplyr)
library(gbm)
library(e1071)
library(ROCR)
library(xgboost)
library(smotefamily)
library(reshape2)
```

## Data Reading and Corrections

```{r}
df <- read.csv("C:/Users/T.SHARMISHTA/OneDrive/Desktop/My files/DS 805/Final Project/dataset/stardata.csv", header = TRUE)

attach(df)
dim(df)
head(df)
```

```{r}
df<- df %>% 
  rename("Temperature" = "Temperature..K.",
         "L" = "Luminosity.L.Lo.",
         "R" = "Radius.R.Ro.",
         "A_M" = "Absolute.magnitude.Mv.",
         "Type" = "Star.type",
         "Color" = "Star.color",
         "Spectral_Class" = "Spectral.Class")
```



## Part 1: Exploratory Data Analysis

```{r}
testdf<-na.omit(df)

nrow(testdf)
nrow(df)
```


```{r}
df$Color<- as.factor(df$Color)
df$Spectral_Class<- as.factor(df$Spectral_Class)
df$Type<- as.factor(df$Type)

head(df)
```

```{r}
summary(df$Color)
```

## Numerical Variables

```{r}
ggplot(df, aes(x=Type, y=Temperature, fill = Type)) + 
  geom_boxplot() +
  scale_fill_brewer(palette="Blues") + 
  theme_minimal()
```

```{r}
ggplot(df, aes(x=Type, y=L, fill = Type)) + 
  geom_boxplot() +
  scale_fill_brewer(palette="Blues") + 
  theme_minimal()
```


```{r}
ggplot(df, aes(x=Type, y=R, fill = Type)) + 
  geom_boxplot() +
  scale_fill_brewer(palette="Blues") + 
  theme_minimal()
```


```{r}
ggplot(df, aes(x=Type, y=A_M, fill = Type)) + 
  geom_boxplot() +
  scale_fill_brewer(palette="Blues") + 
  theme_minimal()
```


## Categorical Variables

```{r}
counts <- table(df$Spectral_Class)
counts
barplot(counts, col = "orange")
```

```{r}
ggplot(df, aes(x = Color, fill = Color)) +
  geom_bar() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

## Test Train Split

```{r}
set.seed(1)
n=round(nrow(df)*.2)
testing=sample(nrow(df), n)
train=df[-testing,]
test=df[testing,]

c(nrow(df), nrow(train), nrow(test))
```


## Part 2: Logistic Regression or LDA

```{r, warning=FALSE}
model.lda = lda(Type~., data=train)
model.lda
```

```{r}
plot(model.lda)
```


```{r}
#LDA Model
lda.pred = predict(model.lda, newdata=test)

#Confusion Matrix
table(test$Type, lda.pred$class)
```

```{r}
plot(test$Type)
plot(lda.pred$class)
```


```{r}
ER1 = mean(test$Type!=lda.pred$class)
ER1

ACC1 = 1-mean(test$Type!=lda.pred$class)
ACC1
```

```{r}
print(paste0("Testing Error of LDA Model: ", round(ER1,4)))
print(paste0("Accuracy of LDA Model: ", round(ACC1,4)))
```



## Part 3: KNN 

```{r}
train$Color <- as.numeric(as.factor(train$Color))
train$Spectral_Class <- as.numeric(as.factor(train$Spectral_Class))
test$Color <- as.numeric(as.factor(test$Color))
test$Spectral_Class <- as.numeric(as.factor(test$Spectral_Class))
```


```{r, warning=FALSE}
#KNN model

knn.train=train[,1:6]
knn.test=test[,1:6]
knn.trainLabels=train[,"Type"]
knn.testLabels=test[,"Type"]


Model.knn <- knn(train = knn.train, test = knn.test, cl = knn.trainLabels, k=5)
```

```{r}
plot(Model.knn)
```

```{r}
#confusion Matrix

table(Model.knn, knn.testLabels)
```

```{r}
#Error rate
ER2 = mean(Model.knn!=knn.testLabels)
ER2

#Accuracy
ACC2 = 1-mean(Model.knn!=knn.testLabels)
ACC2
```

```{r}
print(paste0("Testing Error of KNN Model: ", round(ER2,4)))
print(paste0("Accuracy of KNN Model: ", round(ACC2,4)))
```
## Part-4 Classification trees

## Decision Trees
```{r}
#Gini Split

set.seed(123)
model1 = rpart(Type~., train, method="class", parms=list(split="gini"))
rpart.plot(model1)
```

```{r}
#Information Split

set.seed(123)
model2 = rpart(Type~., train, method="class", parms=list(split="information"))
rpart.plot(model2)
```

```{r}
#prediction model
pred1=predict(model1, newdata=test, type="class")
pred2=predict(model2, newdata=test, type="class")
```

```{r}
#confusion matrix for gini split
cm<-confusionMatrix(
    factor(pred1),
    factor(test$Type)
)

cm
cm$byClass
```

```{r}
#confusion matrix for information split
cm<-confusionMatrix(
    factor(pred2),
    factor(test$Type)
)

cm
cm$byClass
```
```{r}
#Testing Error for Information gain split

ER3 = ce(factor(pred2, levels = 0:5), factor(test$Type, levels = 0:5))
ER3
```
```{r}
#Testing Error for Gini split

ER4 = ce(factor(pred1, levels = 0:5), factor(test$Type, levels = 0:5))
ER4
```
```{r}
print(paste0("Testing Error (Gini Split): ", round(ER4,4)))
print(paste0("Accuracy (Gini Split): ", round(1-ER4,4)))
```
```{r}
print(paste0("Testing Error (Information Split): ", round(ER3,4)))
print(paste0("Accuracy (Information Split): ", round(1-ER3,4)))
```


## Bagging 

```{r}
#Bagging Model

set.seed(123)
model.bag=bagging(factor(Type) ~ ., data=train, coob = TRUE)
print(model.bag)
```

```{r}
#Predictions and Confusion Matrix

pred.bag = predict(model.bag,newdata=test, type = "class")

confusionMatrix(factor(pred.bag, levels = 0:5),
                factor(test$Type, levels = 0:5))
```


```{r}
#Caret model to get importance

ctrl <- trainControl(method = "cv",number = 5)

set.seed(123)  
caret_model <- train(Type~ .,
                            data = train, 
                            method = "treebag",
                            trControl = ctrl)

```

```{r}
#Predictions for Caret Modle
pred_caret <- predict(caret_model, newdata = test, type = "raw")

head(pred_caret,3)

head(predict(caret_model, newdata = test, type = "prob"),3)
```

```{r}
#CM for bagging

confusionMatrix(data=pred_caret, reference=test$Type)
```

```{r}
vip(caret_model)
```

## Random Forest

```{r}
#Random forest

model.rf=randomForest(Type ~ . , data = train , importance=TRUE,proximity=TRUE)
print(model.rf)
```

```{r}
#predictions for Random forest

pred.rf= predict(model.rf, newdata = test, type = "class")

cm4 <- confusionMatrix(data = pred.rf, reference = test$Type)
cm4
cm4$byClass
```

```{r}
#classification error

ce(factor(pred.rf, levels = 0:5), factor(test$Type, levels = 0:5))
```

## Boosting 

```{r}
#boosting model
set.seed(123)
Model1 <- gbm(formula = Type ~ ., distribution="multinomial", data=train, n.trees = 200, cv.folds=5)
print(Model1)
```


```{r}
#CM for boosting model

pModel1 = predict(Model1,n.trees=200, newdata=test,type='response')

labels = colnames(pModel1)[apply(pModel1, 1, which.max)]
cm = confusionMatrix(test$Type, as.factor(labels))
cm
```

```{r}
# Using OOB
ntree.oob.opt=gbm.perf(Model1, method="OOB", oobag.curve=TRUE)
```


```{r}
print(paste0("Optimal ntrees (OOB Estimate): ", ntree.oob.opt))  
```

```{r}
#predictions and AUC

pred.1=predict(object = Model1, 
                  newdata = test,
                  n.trees = ntree.oob.opt)

pModel1.scaled=apply(pred.1, 1, which.max)

auc(test$Type,pModel1.scaled)
```

```{r}
#roc plot for boosting

roc.test = roc(test$Type ~ pModel1.scaled, plot = TRUE, print.auc = TRUE)
```

## Part-5 SVM


```{r}
#SVM Model

svm1<- svm(Type ~ ., data = train, type = "C-classification", kernel = "radial", scale = TRUE)
svm1
```

```{r}
#SVM plot

plot(svm1, train, R~L)
```

```{r}
#predictions and accuracy

pred5=predict(svm1,test)
ER6 = 1-mean(pred5==test$Type)
ACC6 = mean(pred5==test$Type)
```

```{r}
print(paste0("Testing Error of SVM Model: ", round(ER6,4)))
print(paste0("Accuracy of SVM Model: ", round(ACC6,4)))
```

```{r}
#CM for SVM model

cm6<-confusionMatrix(factor(pred5, levels=0:5), factor(test$Type))
cm6
```

